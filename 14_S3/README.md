# ğŸ“¦ Estudos S3 com MinIO

> Ambiente local para estudar AWS S3 sem gastar dinheiro! Usando MinIO, um servidor de armazenamento de objetos compatÃ­vel com a API do S3.

## ğŸ“Œ Sobre

Este projeto demonstra como trabalhar com S3 localmente usando **MinIO**, que Ã© 100% compatÃ­vel com a API do AWS S3. Perfeito para:

- ğŸ“ Estudar sem medo de gastar dinheiro
- ğŸ§ª Testar features do S3
- ğŸš€ Desenvolver aplicaÃ§Ãµes que usam S3

## ğŸ¯ O que Ã© MinIO?

MinIO Ã© um servidor de armazenamento de objetos de alta performance, compatÃ­vel com a API do Amazon S3. VocÃª pode usar o mesmo cÃ³digo que usaria com o S3 da AWS, mas rodando tudo localmente!

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. Subir o MinIO

```bash
make minio-up
```

Isso vai iniciar:

- **API**: http://localhost:9000
- **Console Web**: http://localhost:9001
- **Credenciais**: minioadmin / minioadmin

### 2. Instalar dependÃªncias

```bash
make setup
```

### 3. Rodar a aplicaÃ§Ã£o

```bash
# Exemplos bÃ¡sicos do S3
make run

# Demo de performance (comparaÃ§Ã£o sequencial vs concorrente)
make run-demo
```

## ğŸ“š Exemplos Implementados

O cÃ³digo demonstra as operaÃ§Ãµes mais comuns do S3:

### 1. âœ… Criar Bucket

```go
client.CreateBucket(&s3.CreateBucketInput{
    Bucket: aws.String("meu-bucket"),
})
```

### 2. ğŸ“‹ Listar Buckets

```go
client.ListBuckets(&s3.ListBucketsInput{})
```

### 3. â¬†ï¸ Upload de Arquivo

```go
client.PutObject(&s3.PutObjectInput{
    Bucket: aws.String(bucket),
    Key:    aws.String(filename),
    Body:   bytes.NewReader(content),
})
```

### 4. â¬‡ï¸ Download de Arquivo

```go
client.GetObject(&s3.GetObjectInput{
    Bucket: aws.String(bucket),
    Key:    aws.String(filename),
})
```

### 5. ğŸ”— URL PrÃ©-assinada

```go
req, _ := client.GetObjectRequest(&s3.GetObjectInput{
    Bucket: aws.String(bucket),
    Key:    aws.String(filename),
})
url, _ := req.Presign(15 * time.Minute)
```

### 6. ğŸ—‘ï¸ Deletar Objeto

```go
client.DeleteObject(&s3.DeleteObjectInput{
    Bucket: aws.String(bucket),
    Key:    aws.String(filename),
})
```

## ğŸ® Console Web

Acesse http://localhost:9001 para gerenciar visualmente:

- ğŸ“¦ Buckets
- ğŸ“ Arquivos
- âš™ï¸ ConfiguraÃ§Ãµes
- ğŸ‘¥ UsuÃ¡rios

## ğŸ§ª Testes

```bash
# Testes unitÃ¡rios
make test

# Benchmarks de performance
make benchmark
```

## âš¡ Demo de Performance

O projeto inclui um demo que compara upload sequencial vs concorrente:

```bash
# Demo interativo
make run-demo

# Ou diretamente
go run main.go demo
```

**Resultados esperados:**

- Upload sequencial: ~15-20 segundos (50 arquivos)
- Upload concorrente: ~3-5 segundos (50 arquivos)
- **Melhoria: 3-5x mais rÃ¡pido!**

## âš™ï¸ Mecanismo de Paralelismo

O projeto implementa um **Worker Pool Pattern** com controle de concorrÃªncia para otimizar uploads:

### ğŸ”§ **1. Worker Pool Pattern**

```go
type UploadWorker struct {
    client  *s3.S3
    bucket  string
    sem     chan struct{} // SemÃ¡foro para controlar concorrÃªncia
    results chan UploadResult
    wg      sync.WaitGroup
}
```

**Componentes:**

- **Workers**: goroutines que processam uploads
- **SemÃ¡foro**: controla quantos workers podem rodar simultaneamente
- **WaitGroup**: espera todos os workers terminarem
- **Channel de resultados**: coleta os resultados de cada worker

### âš¡ **2. Controle de ConcorrÃªncia (SemÃ¡foro)**

```go
const maxConcurrentUploads = 10 // MÃ¡ximo 10 uploads simultÃ¢neos

func (w *UploadWorker) uploadFileAsync(filePath string) {
    defer w.wg.Done()
    
    // Controla concorrÃªncia - sÃ³ permite 10 workers simultÃ¢neos
    w.sem <- struct{}{}        // Pega um "slot"
    defer func() { <-w.sem }() // Libera o "slot" quando terminar
    
    // ... faz o upload ...
}
```

**Por que usar semÃ¡foro?**

- **Evita sobrecarga**: nÃ£o cria 1000 goroutines de uma vez
- **Controla recursos**: limita uso de memÃ³ria e conexÃµes
- **Performance otimizada**: 10 workers Ã© o "sweet spot" para S3

### ğŸš€ **3. Goroutines + Channels**

```go
func (w *UploadWorker) UploadMultipleFiles(filePaths []string) []UploadResult {
    // 1. Inicia workers para cada arquivo
    for _, filePath := range filePaths {
        w.wg.Add(1)
        go w.uploadFileAsync(filePath) // Goroutine por arquivo
    }
    
    // 2. Coleta resultados em paralelo
    go func() {
        w.wg.Wait()      // Espera todos terminarem
        close(w.results) // Fecha o channel
    }()
    
    // 3. Coleta todos os resultados
    var results []UploadResult
    for result := range w.results {
        results = append(results, result)
    }
    
    return results
}
```

### ğŸ“Š **4. Fluxo Completo**

```mermaid
Arquivos: [file1.txt, file2.txt, ..., file50.txt]
    â†“
Cria 50 goroutines (mas sÃ³ 10 rodam simultaneamente)
    â†“
SemÃ¡foro controla: 10 workers ativos por vez
    â†“
Cada worker:
  1. Pega um "slot" do semÃ¡foro
  2. Faz upload do arquivo
  3. Envia resultado para o channel
  4. Libera o "slot"
    â†“
WaitGroup espera todos terminarem
    â†“
Coleta todos os resultados
```

### ğŸ”„ **5. Retry com Backoff**

```go
for attempt := 0; attempt < maxRetries; attempt++ {
    if attempt > 0 {
        time.Sleep(time.Duration(attempt) * time.Second) // 1s, 2s, 3s
    }
    
    if err := uploadFile(); err == nil {
        return // Sucesso!
    }
}
```

### ğŸ¯ **6. ComparaÃ§Ã£o de Abordagens**

#### **vs Upload Sequencial:**

```go
// âŒ Sequencial (lento)
for _, file := range files {
    uploadFile(file) // Bloqueia atÃ© terminar
}

// âœ… Concorrente (rÃ¡pido)
for _, file := range files {
    go uploadFileAsync(file) // Roda em paralelo
}
```

#### **vs Sem Controle:**

```go
// âŒ Sem semÃ¡foro (pode estourar memÃ³ria)
for _, file := range files {
    go uploadFile(file) // Cria 1000 goroutines!
}

// âœ… Com semÃ¡foro (controlado)
for _, file := range files {
    go uploadFileAsync(file) // MÃ¡ximo 10 simultÃ¢neos
}
```

### ğŸ’¡ **Resumo do Mecanismo:**

1. **Goroutines** - paralelismo real
2. **SemÃ¡foro** - controle de recursos
3. **WaitGroup** - sincronizaÃ§Ã£o
4. **Channels** - comunicaÃ§Ã£o entre goroutines
5. **Retry** - resiliÃªncia a falhas

Ã‰ um padrÃ£o clÃ¡ssico de **Worker Pool** com **controle de concorrÃªncia** - muito usado em sistemas de alta performance! ğŸš€

## ğŸ§¹ Limpeza

Para parar o MinIO:

```bash
make minio-down
```

Para remover tudo (incluindo volumes):

```bash
make clean
```

## ğŸ’¡ Dicas

1. **Migrando para AWS Real**
   - Basta trocar o endpoint para o da AWS
   - Usar credenciais reais (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
   - Remover `S3ForcePathStyle: true`

2. **PersistÃªncia**
   - Os dados ficam salvos no volume Docker
   - Use `make clean` para resetar tudo

3. **Performance**
   - MinIO Ã© extremamente rÃ¡pido
   - Perfeito para testes de integraÃ§Ã£o

## ğŸ”— Links Ãšteis

- [MinIO Documentation](https://min.io/docs/minio/linux/index.html)
- [AWS SDK for Go](https://aws.amazon.com/sdk-for-go/)
- [AWS S3 API Reference](https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html)

## ğŸš€ PrÃ³ximos Passos

- [ ] Implementar upload de mÃºltiplos arquivos
- [ ] Adicionar streaming de arquivos grandes
- [ ] Implementar versionamento de objetos
- [ ] Adicionar polÃ­ticas de acesso (IAM)
- [ ] Implementar lifecycle policies
